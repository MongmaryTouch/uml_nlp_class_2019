{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Part 1: scikit-learn, nltk, spaCy \n",
    "\n",
    "In this tutorial, you'll get familiar with basic machine learning and NLP libraries needed to process text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "\n",
    "https://scikit-learn.org/stable/\n",
    "\n",
    "Scikit-learn is a universal library that supports many different machine learning algorithms, including various natrual language processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Hello there',\n",
    "    'How are you?',\n",
    "    'Hello! Hello!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'hello', 'how', 'there', 'you']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['Are you doing fine?']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many parameters in the `CountVectorizer` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Hello there',\n",
    "    'How are you?',\n",
    "    'Hello! Hello!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "http://www.nltk.org/\n",
    "\n",
    "The NLTK library contains NLP-specific algorithms for many practical tasks, including word and sentence tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = 'I have a cat.'\n",
    "doc2 = \"He doesn't have a cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'cat', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'does', \"n't\", 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "https://spacy.io/\n",
    "\n",
    "spaCy is a modern industrial-strength natural languge processing library that has a convinient interface and supports many standard tasks, such as parsing, tagging, and named entity recognition.\n",
    "\n",
    "We are going to use a [pretrained spaCy model](https://spacy.io/models/en#en_core_web_lg) for several different tasks. It includes the aforementioned algrotihms as well as word vectors, trained on a large collection of documents form the web ([the Common Crawl](http://commoncrawl.org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('I have a cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I have a cat"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "have"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in doc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-', 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lemma_ for w in doc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"He doesn't have a cat :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'does', \"n't\", 'have', 'a', 'cat', ':(']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-', 'do', 'not', 'have', 'a', 'cat', ':(']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lemma_ for w in doc2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors\n",
    "\n",
    "spaCy also associates a word vector with each word. This vector, and its relative position to other vectors, reflecs the meaning of the word. Similar words will have similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('I have a dog')\n",
    "doc2 = nlp('I have a cat')\n",
    "doc3 = nlp('I have a banana')\n",
    "doc4 = nlp('Congress voted to reopen the government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[3].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0228e-01, -7.6618e-02,  3.7032e-01,  3.2845e-02, -4.1957e-01,\n",
       "        7.2069e-02, -3.7476e-01,  5.7460e-02, -1.2401e-02,  5.2949e-01,\n",
       "       -5.2380e-01, -1.9771e-01, -3.4147e-01,  5.3317e-01, -2.5331e-02,\n",
       "        1.7380e-01,  1.6772e-01,  8.3984e-01,  5.5107e-02,  1.0547e-01,\n",
       "        3.7872e-01,  2.4275e-01,  1.4745e-02,  5.5951e-01,  1.2521e-01,\n",
       "       -6.7596e-01,  3.5842e-01, -4.0028e-02,  9.5949e-02, -5.0690e-01,\n",
       "       -8.5318e-02,  1.7980e-01,  3.3867e-01,  1.3230e-01,  3.1021e-01,\n",
       "        2.1878e-01,  1.6853e-01,  1.9874e-01, -5.7385e-01, -1.0649e-01,\n",
       "        2.6669e-01,  1.2838e-01, -1.2803e-01, -1.3284e-01,  1.2657e-01,\n",
       "        8.6723e-01,  9.6721e-02,  4.8306e-01,  2.1271e-01, -5.4990e-02,\n",
       "       -8.2425e-02,  2.2408e-01,  2.3975e-01, -6.2260e-02,  6.2194e-01,\n",
       "       -5.9900e-01,  4.3201e-01,  2.8143e-01,  3.3842e-02, -4.8815e-01,\n",
       "       -2.1359e-01,  2.7401e-01,  2.4095e-01,  4.5950e-01, -1.8605e-01,\n",
       "       -1.0497e+00, -9.7305e-02, -1.8908e-01, -7.0929e-01,  4.0195e-01,\n",
       "       -1.8768e-01,  5.1687e-01,  1.2520e-01,  8.4150e-01,  1.2097e-01,\n",
       "        8.8239e-02, -2.9196e-02,  1.2151e-03,  5.6825e-02, -2.7421e-01,\n",
       "        2.5564e-01,  6.9793e-02, -2.2258e-01, -3.6006e-01, -2.2402e-01,\n",
       "       -5.3699e-02,  1.2022e+00,  5.4535e-01, -5.7998e-01,  1.0905e-01,\n",
       "        4.2167e-01,  2.0662e-01,  1.2936e-01, -4.1457e-02, -6.6777e-01,\n",
       "        4.0467e-01, -1.5218e-02, -2.7640e-01, -1.5611e-01, -7.9198e-02,\n",
       "        4.0037e-02, -1.2944e-01, -2.4090e-04, -2.6785e-01, -3.8115e-01,\n",
       "       -9.7245e-01,  3.1726e-01, -4.3951e-01,  4.1934e-01,  1.8353e-01,\n",
       "       -1.5260e-01, -1.0808e-01, -1.0358e+00,  7.6217e-02,  1.6519e-01,\n",
       "        2.6526e-04,  1.6616e-01, -1.5281e-01,  1.8123e-01,  7.0274e-01,\n",
       "        5.7956e-03,  5.1664e-02, -5.9745e-02, -2.7551e-01, -3.9049e-01,\n",
       "        6.1132e-02,  5.5430e-01, -8.7997e-02, -4.1681e-01,  3.2826e-01,\n",
       "       -5.2549e-01, -4.4288e-01,  8.2183e-03,  2.4486e-01, -2.2982e-01,\n",
       "       -3.4981e-01,  2.6894e-01,  3.9166e-01, -4.1904e-01,  1.6191e-01,\n",
       "       -2.6263e+00,  6.4134e-01,  3.9743e-01, -1.2868e-01, -3.1946e-01,\n",
       "       -2.5633e-01, -1.2220e-01,  3.2275e-01, -7.9933e-02, -1.5348e-01,\n",
       "        3.1505e-01,  3.0591e-01,  2.6012e-01,  1.8553e-01, -2.4043e-01,\n",
       "        4.2886e-02,  4.0622e-01, -2.4256e-01,  6.3870e-01,  6.9983e-01,\n",
       "       -1.4043e-01,  2.5209e-01,  4.8984e-01, -6.1067e-02, -3.6766e-01,\n",
       "       -5.5089e-01, -3.8265e-01, -2.0843e-01,  2.2832e-01,  5.1218e-01,\n",
       "        2.7868e-01,  4.7652e-01,  4.7951e-02, -3.4008e-01, -3.2873e-01,\n",
       "       -4.1967e-01, -7.5499e-02, -3.8954e-01, -2.9622e-02, -3.4070e-01,\n",
       "        2.2170e-01, -6.2856e-02, -5.1903e-01, -3.7774e-01, -4.3477e-03,\n",
       "       -5.8301e-01, -8.7546e-02, -2.3929e-01, -2.4711e-01, -2.5887e-01,\n",
       "       -2.9894e-01,  1.3715e-01,  2.9892e-02,  3.6544e-02, -4.9665e-01,\n",
       "       -1.8160e-01,  5.2939e-01,  2.1992e-01, -4.4514e-01,  3.7798e-01,\n",
       "       -5.7062e-01, -4.6946e-02,  8.1806e-02,  1.9279e-02,  3.3246e-01,\n",
       "       -1.4620e-01,  1.7156e-01,  3.9981e-01,  3.6217e-01,  1.2816e-01,\n",
       "        3.1644e-01,  3.7569e-01, -7.4690e-02, -4.8480e-02, -3.1401e-01,\n",
       "       -1.9286e-01, -3.1294e-01, -1.7553e-02, -1.7514e-01, -2.7587e-02,\n",
       "       -1.0000e+00,  1.8387e-01,  8.1434e-01, -1.8913e-01,  5.0999e-01,\n",
       "       -9.1960e-03, -1.9295e-03,  2.8189e-01,  2.7247e-02,  4.3409e-01,\n",
       "       -5.4967e-01, -9.7426e-02, -2.4540e-01, -1.7203e-01, -8.8650e-02,\n",
       "       -3.0298e-01, -1.3591e-01, -2.7765e-01,  3.1286e-03,  2.0556e-01,\n",
       "       -1.5772e-01, -5.2308e-01, -6.4701e-01, -3.7014e-01,  6.9393e-02,\n",
       "        1.1401e-01,  2.7594e-01, -1.3875e-01, -2.7268e-01,  6.6891e-01,\n",
       "       -5.6454e-02,  2.4017e-01, -2.6730e-01,  2.9860e-01,  1.0083e-01,\n",
       "        5.5592e-01,  3.2849e-01,  7.6858e-02,  1.5528e-01,  2.5636e-01,\n",
       "       -1.0772e-01, -1.2359e-01,  1.1827e-01, -9.9029e-02, -3.4328e-01,\n",
       "        1.1502e-01, -3.7808e-01, -3.9012e-02, -3.4593e-01, -1.9404e-01,\n",
       "       -3.3580e-01, -6.2334e-02,  2.8919e-01,  2.8032e-01, -5.3741e-01,\n",
       "        6.2794e-01,  5.6955e-02,  6.2147e-01, -2.5282e-01,  4.1670e-01,\n",
       "       -1.0108e-02, -2.5434e-01,  4.0003e-01,  4.2432e-01,  2.2672e-01,\n",
       "        1.7553e-01,  2.3049e-01,  2.8323e-01,  1.3882e-01,  3.1218e-03,\n",
       "        1.7057e-01,  3.6685e-01,  2.5247e-03, -6.4009e-01, -2.9765e-01,\n",
       "        7.8943e-01,  3.3168e-01, -1.1966e+00, -4.7156e-02,  5.3175e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[3].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the similarity between the individual words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dog, cat, banana)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3], doc2[3], doc3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168545"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3].similarity(doc2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24327643"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3].similarity(doc3[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or the whole documents (sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(I have a dog, I have a cat, I have a banana)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1, doc2, doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681672529980867"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753348768953094"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5484653936168645"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model we are using was trained to perform NER, we can easily find all mentions of entities of specific types in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\n",
    "    'Apple is looking at buying U.K. startup for $1 billion. '\n",
    "    'Microsoft acquires Citus Data, creators of a cloud-friendly version of the PostgreSQL database. '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Apple, U.K., $1 billion, Microsoft, Citus Data, PostgreSQL)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple -> ORG\n",
      "U.K. -> GPE\n",
      "$1 billion -> MONEY\n",
      "Microsoft -> ORG\n",
      "Citus Data -> ORG\n",
      "PostgreSQL -> ORG\n"
     ]
    }
   ],
   "source": [
    "for e in doc.ents:\n",
    "    print(e, '->', e.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what is this `GPE` and what tags are available in the documentation: https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple is looking at buying U.K. startup for $1 billion."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents[0].sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
